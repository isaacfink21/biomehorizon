#' Preliminary Data Cleaning and Preperation
#'
#' This function prepares the OTU table and additional datasets for analysis
#' with the \code{horizonplot()} function.
#'
#' The \code{prepanel()} function has 5 main purposes in preparing data sets and
#' other parameters for the main \code{horizonplot()} function:
#'
#' 1) Filter the OTU table to the OTUs displayed on the final horizon plot, and
#' to the samples of just one individual (for datasets with multiple subjects).
#' By default, the "most important" OTUs are selected using four filtering
#' thresholds: \code{thresh_prevalence}, \code{thresh_abundance},
#' \code{thresh_abundance_override}, and \code{thresh_NA}. They can also be
#' manually specified as a vector of OTU IDs using \code{otulist}.
#'
#' 2) Ensure data sets are formatted correctly
#'
#' 3) Set the functions for finding the \code{origin} and horizon band thickness
#' (\code{band.thickness}) of each OTU panel, if the default (NA) or a constant
#' is entered.
#'
#' 4) Set other parameters to their defaults, and ensure correct data types are
#' entered. For boolean values, NA is converted to FALSE.
#'
#' 5) Check for common user errors, such as entering ".8" rather than "80" as a
#' percentage filtering threshold (this will leave a warning message).
#'
#' By default, OTUs are filtered automatically using two thresholds. An
#' abundance threshold (\code{thresh_abundance}) sets the minimum average
#' proportion an OTU must represent across all samples, and a prevalence
#' threshold (\code{thresh_prevalence}) sets the minimum proportion of all
#' samples where this OTU must be present (at least 1 sample read). These
#' thresholds can be used in combination, or alone by setting one of them to
#' \code{0} or \code{NA}.
#'
#' In addition, the user can set a second abundance threshold that overrides the
#' prevalence threshold if it is reached, using
#' \code{thresh_abundance_override}. This is useful for catching OTUs that are
#' abundant for a brief period of time, but are absent from most of the samples,
#' and are nevertheless important to include in analysis. This is disabled by
#' default (\code{thresh_abundance_override == NA}).
#'
#' Finally, a fourth filtering threshold, \code{thresh_NA}, filters out OTUs
#' with missing data in a substantial fraction of the samples. This defaults to
#' eliminating OTUs missing data in >5\% of samples.
#'
#' Alternatively, OTUs can be manually specified in \code{otulist} as a vector
#' of OTU IDs. The order in which these are specified will also determine the
#' arrangement of OTU panels on the horizon plot.
#'
#' @param otudata Data frame representing OTU Table. Assumes first column
#'   "otuid" contains OTU IDs, and all other columns are numeric vectors
#'   containing the number of sample reads for each OTU.
#' @param metadata Data frame representing metadata table; matches samples to
#'   collection dates, and to subject names if applicable. If this data frame is
#'   supplemented, the columns with sample IDs, collection dates and subject
#'   names should be named "sample", "collection_date" and "subject",
#'   respectively. \code{collection_date} must be of class \code{Date}.
#' @param taxonomydata Data frame containing taxonomy information for each OTU,
#'   used for labeling facets. Assumes first column contains OTU IDs, and all
#'   other columns are character vectors representing taxonomic ranks, starting
#'   from Kingdom and going as far as Species. Must be the same length as number
#'   of OTUs post-filtering. Defaults to NA (do not label by taxonomy).
#' @param thresh_prevalence numeric threshold for OTU filtering. Minimum % of
#'   total samples in which OTU must be present to be included in analysis
#'   (defaults to 80).
#' @param thresh_abundance numeric threshold for OTU filtering. Minimum % of
#'   total sample reads the OTU must constitute to be included in analysis
#'   (defaults to 0.5).
#' @param thresh_abundance_override numeric threshold for OTU filtering. Minimum
#'   % of total sample reads the OTU must constitute to override all other
#'   standards, and be included in analysis (defaults to NA: disabled).
#' @param thresh_NA numeric threshold for OTU filtering. Maximum % of samples
#'   with missing data (defaults to 5).
#' @param otulist character vector specifying OTU IDs for manual selection. Also
#'   determines the order from top to bottom of OTU panels displayed on the
#'   horizon plot. Defaults to NA (use filtering thresholds). In this case, OTU
#'   panels will be ordered alphabetically by OTU ID.
#' @param regularInterval integer. For regularized data, this specifies the
#'   fixed interval of days seperating each sample timepoint. If this value is
#'   20, for example, new timepoints will be created at 1, 21, 41, 61, etc. To
#'   leave data irregularly spaced, do not specify a number here. Defaults to NA
#'   (do not regularize).
#' @param maxGap numeric specifying the maximum number of days between the
#'   previous and subsequent irregular timepoints in order to interpolate a new
#'   timepoint. If the distance between the nearest time points exceeds the
#'   threshold specified by \code{maxGap}, all OTU values for that time point
#'   will be set to NA, and a scale break in the time axis will appear on the
#'   horizon plot. Must be an integer > 0.
#' @param subj character. For datasets with multiple individual microbiomes,
#'   specifies the subject to be analyzed, and filters out samples of all other
#'   subjects. Subject names should be described in metadata under the variable
#'   "sname". Defaults to NA (assume all samples are from one individual; do not
#'   filter by subject name).
#' @param band.thickness The height of each horizontal band (denoted by a unique
#'   color), i.e. the size of the scale of a horizon subplot.  There are three
#'   options: \itemize{ \item If \code{NA}, the default, the band thickness will
#'   be evaluated using the function \code{function(y) {max((abs(y -
#'   origin(y))), na.rm=TRUE) / nbands}}. This calculates the maximum extreme
#'   (lowest or highest abundance value) divided by the number of bands. \item A
#'   \code{function} will be called with a single argument, the sample values
#'   for one OTU, to evaluate a unique band thickness for each panel based on
#'   its sample values. The return value must be numeric. \item A numeric
#'   constant, providing a fixed band thickness for all OTUs. }
#' @param origin The baseline (value=0, the base of the first positive band) for
#'   horizon subplots. There are three options: \itemize{ \item If \code{NA},
#'   the default, the origin will be evaluated separately for each OTU using the
#'   median of the sample values. \item A \code{function} will be called with a
#'   single argument, a numeric vector representing the sample values for one
#'   OTU, to evaluate a unique origin for each panel. The return value must be
#'   numeric. \item A numeric constant, providing a fixed origin value for all
#'   OTUs. }
#' @param facetLabelsByTaxonomy If TRUE, label facets by taxonomy, using
#'   \code{taxonomydata}. Facets will be labelled using the most specific
#'   classification available for each OTU. If FALSE (default), label facets by
#'   OTU ID.
#' @param customFacetLabels Use a custom character vector to label facets. Must
#'   be the same length as the number of OTUs post-filtering. Facet subplots
#'   will be displayed in the order specified by these labels, so if you would
#'   like to arrange OTU rows in a particular order, use this vector. Overrides
#'   facetLabelsByTaxonomy, but if set to NA (the default),
#'   facetLabelsByTaxonomy is used instead.
#' @param interpolate_NA logical. Should NA values be interpolated or set to
#'   value=0? If TRUE (default), NA values are interpolated using previous and
#'   subsequent OTU values. If FALSE, they are set to value=0. Note that this
#'   only applies to sample timepoints that contain values for some OTUs; if a
#'   sample consists entirely of NAs, it will be treated as a break in the
#'   timescale (see \code{maxGap}).
#' @param formatStep If FALSE (default), horizon plot is a line graph. If TRUE,
#'   horizon plot is formatted as a step graph, with steps horizontal and then
#'   vertical.
#' @param col.outline character. Hexadecimal color of panel borders and the
#'   outline on top of y-values for each band. Defaults to light gray (#CCCCCC).
#'   Can be set to \code{NA} to remove the outline.
#' @param col.brew character vector containing hexadecimal color codes that
#'   correspond to horizon bands. Colors should be specified from the most
#'   negative band to the most positive band. The length of this vector also
#'   determines \code{nbands}, and must be an even number greater than 6
#'   (minimum of 3 bands). Defaults to a sampling of 8 colors from a 10-color
#'   Red-Blue gradient from RColorBrewer,
#'   \code{brewer.pal(10,"RdBu")[c(1:4,6:10)]}. In this set, red indicates
#'   negative bands while blue indicates positive bands.
#'
#' @return Returns a list containing the appropriate arguments for the
#'   horizonplot function. This result list should then be inputted into
#'   \code{horizonplot()} to produce the graph. The user should not need to
#'   alter any parameters in this list before using them in \code{horizonplot},
#'   but this preliminary function allows the user to check the refined
#'   parameters in case of an error in \code{horizonplot}.
#'
#' @examples
#' # Pass just the OTU table to prepanel, and it will assume all samples belong
#' # to the same subject.
#' prepanel(otusample)
#'
#' # Supplement metadata and a subject name, and it will select samples from
#' # just one subject (this is what you should do with more than one subject).
#' prepanel(otusample, metadatasample, subj="subject_1")
#'
#' # Pass taxonomydata to prepanel if you want to label facets by taxonomy
#' # rather than by OTU ID.
#' prepanel(otusample, metadatasample, taxonomysample, subj="subject_1",
#' facetLabelsByTaxonomy=TRUE)
#'
#' # OTU filtering using both a prevalence and an abundance standard (default)
#' prepanel(otusample, metadatasample, subj="subject_1", thresh_prevalence=75,
#' thresh_abundance=0.75)
#'
#' # OTU filtering using just an abundance standard
#' prepanel(otusample, metadatasample, subj="subject_1", thresh_prevalence=NA,
#' thresh_abundance=0.75)
#'
#' # If an OTU's average abundance reaches a high enough threshold, override
#' # other standards and include it in analysis
#' prepanel(otusample, metadatasample, subj="subject_1", thresh_prevalence=90,
#' thresh_abundance=0.75, thresh_abundance_override=1.5)
#'
#' # Filter OTUs where >2% samples are NA values
#' prepanel(otusample, metadatasample, subj="subject_1", thresh_NA=2)
#'
#' # You can also manually select OTUs by OTU ID
#' prepanel(otusample, metadatasample, subj="subject_1",
#' otulist=c("otu_1000","otu_1243","otu_1530","otu_6821","otu_7737"))
#'
#' # Manual selection can be used to specify the order OTUs will appear on
#' # the horizon plot. For example, these two datasets have identical OTUs, but
#' # they are ordered differently.
#' params <- prepanel(otusample, metadatasample, subj="subject_1",
#' thresh_prevalence=95, thresh_abundance=1.5)
#' params[[1]]$otuid
#' params <- prepanel(otusample, metadatasample, subj="subject_1",
#' otulist=c("otu_2526","otu_1530", "otu_7737", "otu_6821", "otu_3773",
#' "otu_2457", "otu_1243", "otu_2378"))
#' params[[1]]$otuid
#'
#' # The origin and band.thickness variables can be set to either a numeric
#' # constant or a function that evaluates seperately for every OTU subpanel based
#' # on its sample values.
#'
#' # Use a fixed origin of 5% for all OTU subpanels
#' prepanel(otusample, metadatasample, subj="subject_1", origin=5)
#'
#' # Evaluate a different origin for each OTU subpanel using a custom function
#' prepanel(otusample, metadatasample, subj="subject_1",
#' origin=function(y){mad(y, na.rm=TRUE)})
#'
#' @importFrom magrittr %>%
#'
#' @export
prepanel <- function(otudata, metadata=NA, taxonomydata=NA,
                     thresh_prevalence=80, thresh_abundance=0.5, thresh_abundance_override=NA, thresh_NA=5,
                     regularInterval=NA, maxGap=NA,
                     otulist=NA,
                     subj=NA,
                     band.thickness=NA, origin=NA,
                     facetLabelsByTaxonomy=FALSE, customFacetLabels=NA,
                     interpolate_NA=TRUE, formatStep=FALSE, col.outline="#CCCCCC",
                     col.brew=c("#67001F", "#B2182B", "#D6604D", "#F4A582", "#92C5DE", "#4393C3", "#2166AC", "#053061"))
{
  # Check and fix otudata format
  if(FALSE %in% (sapply(otudata,class)[-1] == "integer")) {
    stop("All columns of otudata except the first must be of class integer")
  }
  colnames(otudata)[1] <- "otuid"

  # Convert data to %
  otudata[,-1] <- apply(otudata[,-1],2,function(x){100*x/sum(as.numeric(x),na.rm=TRUE)})

  # Check filtering thresholds
  if(is.na(thresh_prevalence) | class(thresh_prevalence) != "numeric") {
    stop("thresh_prevalence must be of type numeric")
  }
  if(thresh_prevalence > 100 | thresh_prevalence < 0) {
    stop("thresh_prevalence must be a number between 0 and 100")
  }
  if(thresh_prevalence < 1 & thresh_prevalence > 0) {
    warning(paste("thresh_prevalence is less than 1%, and is supposed to be a number between 0 and 100. Did you mean thresh_prevalence=",100*thresh_prevalence,"?",sep=""))
  }
  if(is.na(thresh_abundance) | class(thresh_abundance) != "numeric") {
    stop("thresh_abundance must be of type numeric")
  }
  if(thresh_abundance > 100 | thresh_abundance < 0) {
    stop("thresh_abundance must be a number between 0 and 100")
  }
  if(!is.na(thresh_abundance_override)) {
    if(class(thresh_abundance_override) != "numeric") {
      stop("thresh_abundance_override must be of type numeric")
    }
    if(thresh_abundance_override<0 | thresh_abundance_override>100) {
      stop("thresh_abundance_override must be a number between 0 and 100 (or NA)")
    }
  }
  if(is.na(thresh_NA) | class(thresh_NA) != "numeric") {
    stop("thresh_NA must be of type numeric")
  }
  if(thresh_NA > 100 | thresh_NA < 0) {
    stop("thresh_NA must be a number between 0 and 100")
  }

  # Filter otudata
  if(is.na(otulist)) {
    otudata$nonzero <- rowSums(otudata[,-1] != 0, na.rm = TRUE)
    otudata$prevalence <- 100 * otudata$nonzero/(ncol(otudata)-2)
    otudata$abundance <- rowSums(otudata[,2:(ncol(otudata)-2)], na.rm=TRUE) / otudata$nonzero
    otudata$nacount <- rowSums(is.na(otudata[,2:(ncol(otudata)-3)]))
    otudata <- dplyr::filter(otudata, (100 * nacount / (ncol(otudata)-5) < thresh_NA) & ((prevalence > thresh_prevalence & abundance > thresh_abundance) | (!is.na(thresh_abundance_override) & abundance > thresh_abundance_override))) %>%
      dplyr::select(-nonzero, -prevalence, -abundance, -nacount)
  } else {
    otudata <- otudata %>% dplyr::filter(otuid %in% otulist)
    if(nrow(otudata)==0) {
      stop("no values in otulist match otuids in otudata; all rows filtered out")
    }
  }

  # Filter metadata and otudata samples by subject
  if(!is.na(subj)) {
    if(!is.data.frame(metadata)) {
      stop("cannot filter otudata by subject without metadata on sample and subject")
    }
    if(!("subject" %in% colnames(metadata))) {
      stop("metadata must contain variable \"subject\" to filter by subject")
    }
    metadata <- metadata %>% dplyr::filter(subject==subj)
    if(!("sample" %in% colnames(metadata))) {
      stop("metadata must contain variable sample")
    }
    otudata[,-1] <- otudata[,-1][,colnames(otudata) %in% metadata$sample]
  }

  # Determine timestamps, if metadata provided; select and order otudata samples
  if(is.data.frame(metadata)) {
    if("collection_date" %in% colnames(metadata)) {
      if(class(metadata$collection_date)=="Date") {
        if(!("sample" %in% colnames(metadata))) {
          stop("metadata must contain variable sample")
        }
        if(nrow(metadata) != (ncol(otudata)-1)) {
          warning("Number of sample rows in metadata does not match number of sample columns in otudata. Sample columns not in metadata have been removed.")
        }
        if(NA %in% metadata$collection_date) {
          stop("NAs found in metadata$collection_date")
        }

        metadata <- metadata %>%
          dplyr::mutate(collection_date=as.numeric(collection_date)) %>%
          dplyr::arrange(collection_date)
        if(sum(metadata$sample %in% colnames(otudata)) < (ncol(otudata)-1)) {
          colnames(otudata)[-1] <- as.character(metadata$sample)
          warning("Some columns in otudata have no match in metadata. Assigning sample names based on collection_date.")
        }

        tempdf <- otudata[,-1]
        tempdf <- tempdf %>% dplyr::select(which(colnames(tempdf) %in% as.character(metadata$sample)))
        otudata <- cbind(otuid=otudata$otuid,tempdf)

        timestamps <- 1 + metadata$collection_date - metadata$collection_date[1]
      } else {
        stop("variable collection_date in metadata must be of class Date")
      }
    } else {
      stop("metadata must contain variable collection_date")
    }
  } else {
    timestamps <- NA
  }

  # Check taxonomydata format
  if(is.data.frame(taxonomydata)) {
    if(ncol(taxonomydata) > 8) {
      stop("taxonomydata has more than 8 columns; the function does not support classification past Species")
    }
    taxonomynames <- c("Kingdom","Phylum","Class","Order","Family","Genus","Species")
    colnames(taxonomydata) <- c("otuid",taxonomynames[1:(ncol(taxonomydata)-1)])
    taxonomydata <- taxonomydata %>% dplyr::filter(otuid %in% otudata$otuid)

    if(nrow(taxonomydata) != nrow(otudata)) {
      stop("number of OTU rows in taxonomydata does not match number of OTU rows in otudata")
    }
  } else {
    taxonomydata <- NA
  }

  # Set variables to correct values
  if(!is.na(regularInterval) & regularInterval<=0) {
    regularInterval <- NA
  }
  if(is.na(regularInterval)) {
    maxGap <- NA
  } else {
    if(!is.na(maxGap) & maxGap < regularInterval) {
      maxGap <- NA
      warning("maxGap is less than regularInterval; setting to default maxGap=NA")
    }
  }
  if(is.na(formatStep)) {
    formatStep <- FALSE
  } else {
    if(class(formatStep) != "logical") {
      stop("formatStep must be of type logical")
    }
  }
  if(is.na(interpolate_NA)) {
    interpolate_NA <- FALSE
  } else {
    if(class(interpolate_NA) != "logical") {
      stop("interpolate_NA must be of type logical")
    }
  }
  if(is.na(facetLabelsByTaxonomy)) {
    facetLabelsByTaxonomy <- FALSE
  } else {
    if(class(facetLabelsByTaxonomy) != "logical") {
      stop("facetLabelsByTaxonomy must be of type logical")
    }
  }
  if(!is.na(customFacetLabels) & length(customFacetLabels) != nrow(otudata)) {
    warning("customFacetLabels is not the same length as number of OTUs, using default labels.")
    customFacetLabels <- NA
  }
  if(is.na(col.outline)) {
    col.outline <- "#CCCCCC"
  } else {
    if(class(col.outline) != "character") {
      stop("col.outline must be a hexadecimal color of type character")
    } else {
      if(nchar(col.outline) != 7) {
        stop("col.outline must be in hexadecimal color format (e.g. #CCCCCC)")
      }
    }
  }
  # Colorset for bands (default 3 bands)
  if(NA %in% col.brew) {
    col.brew <- c("#67001F", "#B2182B", "#D6604D", "#F4A582", "#92C5DE", "#4393C3", "#2166AC", "#053061")
  } else {
    if(class(col.brew) != "character") {
      warning("col.brew must be a hexadecimal color vector of type character. Using default colorset.")
      col.brew <- c("#67001F", "#B2182B", "#D6604D", "#F4A582", "#92C5DE", "#4393C3", "#2166AC", "#053061")
    }
    if(length(col.brew) < 6) {
      warning("col.brew has <6 color values, not enough for at least 3 bands. Using default colorset.")
      col.brew <- c("#67001F", "#B2182B", "#D6604D", "#F4A582", "#92C5DE", "#4393C3", "#2166AC", "#053061")
    }
    if(length(col.brew) %% 2 != 0) {
      warning("col.brew has an odd number of color values. Using default colorset.")
      col.brew <- c("#67001F", "#B2182B", "#D6604D", "#F4A582", "#92C5DE", "#4393C3", "#2166AC", "#053061")
    }
  }
  nbands <- length(col.brew) / 2

  # Set functions
  if(is.na(origin)) {
    origin <- function(y) {
      median(y, na.rm=TRUE)
    }
  } else {
    if(is.numeric(origin)) {
      originconstant <- origin
      origin <- function(y) { originconstant }
    } else {
      if(!is.function(origin)) {
        warning("origin must be a function operating on a numeric vector. Using default function (median).")
        origin <- function(y) {
          median(y, na.rm=TRUE)
        }
      }
    }
  }

  if(is.na(band.thickness)) {
    band.thickness <- function(y) {
      max((abs(y - origin(y))), na.rm=TRUE) / nbands
    }
  } else {
    if(is.numeric(band.thickness)) {
      bandthicknessconstant <- band.thickness
      band.thickness <- function(y) { bandthicknessconstant }
    } else {
      if(!is.function(band.thickness)) {
        warning("band.thickness must be a function operating on a numeric vector. Using default function.")
        band.thickness <- function(y) {
          max((abs(y - origin(y))), na.rm=TRUE) / nbands
        }
      }
    }
  }

  fill_NA <- ifelse(interpolate_NA, function(y){zoo::na.approx(y)}, function(y){zoo::na.fill(y,0)})

  cat("Constructed an OTU table and other variables with the following settings:",
      paste("thresh_prevalence:", thresh_prevalence),
      paste("thresh_abundance:", thresh_abundance),
      paste("thresh_abundance_override:", thresh_abundance_override),
      paste("thresh_NA:", thresh_NA),
      paste("subj:", subj),
      sep="\n")

  list(otudata,taxonomydata,timestamps,otulist,
       regularInterval,maxGap,band.thickness,origin,
       facetLabelsByTaxonomy,customFacetLabels,
       fill_NA,nbands,formatStep,col.brew,col.outline)
}

#' Construct a Microbiome Horizon Plot
#'
#' This is the main function that constructs and returns the microbiome horizon
#' plot.
#'
#' After data sets and other parameters have been properly formatted and checked
#' for errors in the \code{prepanel} function, they are entered into this
#' function, which constructs and returns the horizon plot. All customizations
#' of the graph should be specified in \code{prepanel()} and not here; no
#' alteratons should be made to the output list before it is entered into this
#' function.
#'
#' The refined version of \code{otudata} used in this function represents a
#' filtered OTU table, containing only the OTUs to be displayed on the graph,
#' and only the samples belonging to the subject selected. Sample values in this
#' refined table reflect difference in fractional abundance from the origin
#' value. Values are converted from raw sample reads to proportions of the
#' entire sample represented by a given OTU, and then the proportion values
#' within each OTU are centered to their respective \code{origin} values.
#'
#' The refined \code{taxonomydata} is filtered to just the OTUs in
#' \code{otudata}.
#'
#' @section Irregular Data:
#'
#' A common problem faced in visualizing time series data is plotting data
#'   spaced at irregular time intervals. A common solution for this problem is
#'   interpolating values at regular time intervals using nearby data. However,
#'   since microbiome data can change drastically in short periods of time, it
#'   doesn't make sense to interpolate through large timespans, and thus the
#'   function gives several options to plot irregular data as accurately as
#'   possible.
#'
#'   \enumerate{ \item Plot "real values" but with an inaccurate timescale. For
#'   this default option, samples will be plotted next to each other regardless
#'   of their timestamps. This is most accurate in that timepoints are plotted
#'   directly from sample values, but risks being misleading if the timescale is
#'   not clearly marked as inconsistent.  Additionally, this option removes the
#'   ability to visually compare temporal differences within the same plot.
#'   \item Plot artificial values but with a regularized timescale. New values
#'   can be interpolated using existing ones at a regular interval of time
#'   specified by \code{regularInterval}. The first sample is plotted as "day
#'   1," and a new value is interpolated using the closest previous and
#'   subsequent sample timepoints at a fixed interval throughout the rest of the
#'   data.  This "regularization" of the data allows for quick visual comparison
#'   of microbiome changes within the plot. The downside of this method is that
#'   "real" values are not plotted (except for rare cases where a sample
#'   timepoint happens to fall on the regular interval), and innaccuracies are
#'   created through interpolation. This is especially true given the
#'   continuous, rapid changes of bacterial abundances within the microbiome.
#'   \item Compromise between accuracy of values and a regular timescale:
#'   interpolation within clusters of closely-spaced data, which are seperated
#'   by breaks in the time axis. This allows for temporal comparison within each
#'   cluster of timepoints and avoids interpolating across large timespans. This
#'   method is practical for datasets where samples are collected irregularly,
#'   arranged in periodic clusters of closely-spaced data seperated by larger
#'   timespans with fewer samples. Clustering is done by specifying a value for
#'   \code{maxGap}, which defines the threshold of time without data to seperate
#'   clusters.}
#'
#' @param parameterList The list of parameters for constructing the horizon
#'   plot. This should come directly from the output list of the
#'   \code{prepanel()} function, without alteration. The 15 parameters, in
#'   order, are \code{otudata}, \code{taxonomydata}, \code{timestamps},
#'   \code{otulist}, \code{regularInterval}, \code{maxGap},
#'   \code{band.thickness}, \code{origin}, \code{facetLabelsByTaxonomy},
#'   \code{customFacetLabels}, \code{fill_NA}, \code{nbands}, \code{formatStep},
#'   \code{col.brew}, and \code{col.outline}.
#'
#'   Four of the parameters are not arguments of the \code{prepanel()} function,
#'   and are described below:
#'
#'   \code{timestamps} is an integer vector containing the time (days) each
#'   sample was collected, retrieved from the \code{collection_date} variable of
#'   \code{metadata}. The first element is designated as day 1.
#'
#'   \code{nbands} is an integer representing the number of positive bands (each
#'   denoted by a unique color) on the horizon plot, determined by the length of
#'   the color vector (\code{col.brew}) supplied to \code{prepanel()}. The
#'   default 8-element colorscale for \code{col.brew} will set \code{nbands} to
#'   4, producing four positive and four negative bands.
#'
#'   \code{fill_NA} is the function that fills missing data in \code{otudata},
#'   based on the boolean value \code{interpolate_NA} specified in
#'   \code{prepanel()}. This will be set to either assign missing data values to
#'   zero (\code{interpolate_NA == TRUE}) or interpolate them using adjacent
#'   data within the same OTU (\code{interpolate_NA == FALSE}). (Note: missing
#'   data in this case does not include entire timepoints without data, in which
#'   case data is either interpolated or a break in the time axis is created.)
#'
#' @return Returns the horizon plot as a \code{ggplot} object.
#'
#' @examples
#'
#'
#'
#' ---
#'
#'
#'
#' irregular data plotted next to each other
#' regular interval interpolated each 100 days
#' creating a graph break for each timepoint with no adjacent "real" timepoints for 300 days.
#'   This is valuable for datasets like this were data is collected in temporal clusters, so
#'   interpolating is accurate within clusters but is too far between clusters.
#'
#' # OTU table
#'
#' @import ggplot2
#' @importFrom magrittr %>%
#'
#' @export
horizonplot <- function(parameterList) {
  if(length(parameterList) != 15) {
    stop("parameterList must be of length 15; use output list from prepanel function")
  }

  otudata <- parameterList[[1]]
  taxonomydata <- parameterList[[2]]
  timestamps <- parameterList[[3]]
  otulist <- parameterList[[4]]
  regularInterval <- parameterList[[5]]
  maxGap <- parameterList[[6]]
  band.thickness <- parameterList[[7]]
  origin <- parameterList[[8]]
  facetLabelsByTaxonomy <- parameterList[[9]]
  customFacetLabels <- parameterList[[10]]
  fill_NA <- parameterList[[11]]
  nbands <- parameterList[[12]]
  formatStep <- parameterList[[13]]
  col.brew <- parameterList[[14]]
  col.outline <- parameterList[[15]]

  # Origin-center, save band-thicknesses into new column.
  otudata$bt <- numeric(nrow(otudata))
  for(i in 1:nrow(otudata)) {
    otudata[i,2:(ncol(otudata)-1)] <- as.numeric(otudata[i,2:(ncol(otudata)-1)]) - origin(as.numeric(otudata[i,2:(ncol(otudata)-1)]))
    otudata$bt[i] <- band.thickness(as.numeric(otudata[i,2:(ncol(otudata)-1)]))
  }

  # Change sample IDs to corresponding dates and melt data
  if(!is.na(regularInterval)) {
    newTimestamps <- seq(from=1, to=max(timestamps), by=regularInterval)
    indPrev <- numeric()
    for(i in 1:length(newTimestamps)) {
      indPrev[i] <- max(which(timestamps <= newTimestamps[i]))
    }

    templist <- list()
    for(i in 1:length(newTimestamps)) {
      y1 <- otudata[,1+indPrev[i]]
      y2 <- otudata[,2+indPrev[i]]
      t1 <- timestamps[indPrev[i]]
      t2 <- timestamps[indPrev[i]+1]
      Ti <- newTimestamps[i]

      templist[[i]] <- pmin(y1,y2) + (Ti-t1)*(abs(y2-y1)/(t2-t1))

      if(!is.na(maxGap) & !(Ti==t1 | Ti==t2) & (abs(Ti-t1) > maxGap | abs(Ti-t2) > maxGap)) {
        templist[[i]] <- NA
      }
    }
    newdata <- as.data.frame(templist)
    rm(templist)
    colnames(newdata) <- newTimestamps
    otudata <- cbind(otuid=otudata$otuid,newdata,bt=otudata$bt)
  } else {
    colnames(otudata)[2:(ncol(otudata)-1)] <- as.character(1:(ncol(otudata)-2))
  }

  # Fill NAs using selected method
  if(is.na(regularInterval) | is.na(maxGap)) {
    otudata[,2:(ncol(otudata)-1)] <- as.data.frame(t(fill_NA(t(otudata[,2:(ncol(otudata)-1)]))))
  } else {
    nums <- otudata %>% dplyr::select(-otuid, -bt)
    breakpts <- as.numeric(c(-1*regularInterval,colnames(nums)[colSums(is.na(nums))==nrow(nums)],regularInterval+as.numeric(colnames(nums)[ncol(nums)])))
    naCols <- as.character(breakpts[c(-1,-length(breakpts))])
    otudata <- otudata %>% dplyr::select(-naCols)
    rm(naCols)
  }

  # formatStep = FALSE: add extra points for interpolation
  extrapts <- data.frame(character(),numeric(),numeric(),numeric())
  colnames(extrapts) <- c("otuid","bt","day","value")
  dX <- ifelse(is.na(regularInterval), 1, regularInterval)

  if(!formatStep) {
    for(r in 1:nrow(otudata)) {
      bt <- otudata[r,ncol(otudata)]
      nums <- otudata[r,c(-1,-ncol(otudata))]

      bands <- 1 # Every point is at least a member of the lowest band
      for(n in (-1*nbands+1):(nbands-1)) {
        bands <- bands + (nums > n*bt)
      }
      bands <- bands-nbands

      x <- numeric()
      y <- numeric()

      for(i in 1:(2*nbands-1)) {
        # UPCROSSINGS
        upcrossings <- as.numeric(which(bands-dplyr::lead(bands) == -i)) # The indices where the sample is about to increase band
        if(length(upcrossings>0)) {
          y1 <- as.numeric(nums[upcrossings]) # Note that this is a dataframe without conversion...
          y2 <- as.numeric(nums[upcrossings+1])
          for(j in 0:(i-1)) {
            # Add a point.
            newY <- bt*(bands[upcrossings]+j)
            newX <- as.numeric(names(nums)[upcrossings]) + ((newY-y1)/(y2-y1)) * dX

            x <- c(x,newX)
            y <- c(y,newY)
          }
        }

        # DOWNCROSSINGS
        downcrossings <- as.numeric(which(bands-dplyr::lead(bands) == i)) # The indices where the sample is about to decrease band
        if(length(downcrossings>0)) {
          y1 <- as.numeric(nums[downcrossings])
          y2 <- as.numeric(nums[downcrossings+1])
          for(j in 0:(i-1)) {
            # Add a point.
            newY <- bt*(bands[downcrossings+1]+j)
            newX <- as.numeric(names(nums)[downcrossings])+dX - ((newY-y2)/(y1-y2)) * dX

            x <- c(x,newX)
            y <- c(y,newY)
          }
        }
      }

      if(length(x)>0) {
        extrapts <- rbind.data.frame(extrapts, data.frame(otuid=otudata[r,1],bt=bt,day=as.character(x),value=y, stringsAsFactors=FALSE))
      }
    }
  }

  # Melt data into a date column
  otudata <- otudata %>% tidyr::gather(key=day,value=value,-c("otuid","bt"))
  otudata$otuid <- as.character(otudata$otuid)
  otudata$day <- as.character(otudata$day)

  otudata <- rbind.data.frame(otudata,extrapts) # Merge regular points and intermediate points

  # Add band columns
  for (i in 1:nbands) {
    #positive
    otudata[,paste("ypos",i,sep="")] <- ifelse(otudata$value > 0,
                                               ifelse(abs(otudata$value) > otudata$bt * i,
                                                      otudata$bt,
                                                      ifelse(abs(otudata$value) - (otudata$bt * (i - 1)) > 0, abs(otudata$value) - (otudata$bt * (i - 1)), 0)), 0)
    #negative
    otudata[,paste("yneg",i,sep="")] <- ifelse(otudata$value < 0,
                                               ifelse(abs(otudata$value) > otudata$bt * i,
                                                      otudata$bt,
                                                      ifelse(abs(otudata$value) - (otudata$bt * (i - 1)) > 0, abs(otudata$value) - (otudata$bt * (i - 1)), 0)), 0)
  }

  # Melt data and graph it
  otudata <- otudata[,c(1,3,5:ncol(otudata))] %>% tidyr::gather(key=band,value=value,-(1:2))

  colorcodes <- numeric(nbands*2)
  for(i in 1:nbands) {
    colorcodes[i] <- paste("yneg",nbands-i+1,sep="")
  }
  for(i in (nbands+1):(nbands*2)) {
    colorcodes[i] <- paste("ypos",i-nbands,sep="")
  }
  names(col.brew) <- colorcodes

  if(formatStep) {
    # Add additional steps to dataframe
    otudata <- otudata %>% dplyr::arrange(otuid)
    otudata_extraSteps <- otudata %>% dplyr::mutate(value = ifelse(day==1,NA,dplyr::lag(value)))
    otudata <- dplyr::bind_rows(old = otudata, new = otudata_extraSteps, .id = "source") %>%
      dplyr::arrange(otuid, band, day, source)
  }

  if(!is.na(maxGap) && length(breakpts)!=0) {
    otudata <- addFacets(otudata,breakpts,regularInterval)
  }

  # Arrange OTU rows according to order of otuid
  if(!is.na(otulist)) {
    otudata <- otudata %>% dplyr::arrange(as.numeric(day),band,factor(otuid,levels=otulist))
  }

  if(!is.na(customFacetLabels)) {
    facetLabels <- customFacetLabels
  } else {

    if(facetLabelsByTaxonomy & is.data.frame(taxonomydata)) {
      facetLabels <- taxonomydata %>%
        dplyr::arrange(otudata$otuid[1:nrow(taxonomydata)]) %>%
        apply(1,function(x){dplyr::last(x[!is.na(x)])})
    } else {
      facetLabels <- as.character(otudata$otuid)
    }

  }
  names(facetLabels) <- otudata$otuid[1:nrow(taxonomydata)]

  p <- ggplot(data=otudata) +
    geom_area(aes(x = as.numeric(day), y = value, fill=band), position="identity", color=col.outline) +  #this means not stacked
    scale_fill_manual(values=col.brew) +
    theme_bw() +
    theme(axis.text.x=element_text(size=16), axis.text.y=element_blank(), axis.ticks.y=element_blank(), panel.grid=element_blank(), panel.border=element_rect(color=col.outline), strip.text.y=element_text(angle=180), panel.spacing.y=unit(0, units="cm")) +
    guides(fill=FALSE) +
    scale_y_continuous(expand = c(0,0)) + scale_x_continuous(expand = c(0,0)) + # remove margins between plot and panel
    xlab(element_blank()) + ylab(element_blank())

  if(!is.na(maxGap) && maxGap!=0 && length(breakpts)!=0) {
    p <- p + facet_grid(otuid ~ type, scales="free", labeller=labeller(otuid=facetLabels), switch="y") #do new subplot for each otu
  } else {
    p <- p + facet_grid(otuid ~ ., scales="free", labeller=labeller(otuid=facetLabels), switch="y") #do new subplot for each otu
  }
  breakpts <- numeric()

  cat("Constructed a horizon plot with the following settings:",
      paste("regularInterval:", regularInterval),
      paste("maxGap:", maxGap),
      paste("facetLabelsByTaxonomy:", facetLabelsByTaxonomy),
      paste("formatStep:", formatStep),
      paste("nbands:", nbands),
      paste("origin:", deparse(origin)),
      paste("band.thickness:", deparse(band.thickness)),
      paste("fill_NA:", deparse(fill_NA)),
      sep="\n")

  p
}

# Internal function used to create breaks in the time scale through facetting.
addFacets <- function(x, boundaries, regularInterval) {
  if(!is.data.frame(x)) {
    stop("x must be of type data frame")
  }

  for(i in 1:nrow(x)) {
    for(j in 1:length(boundaries)) {
      if(as.numeric(x$day[i]) >= boundaries[j]+regularInterval & as.numeric(x$day[i]) <= boundaries[j+1]-regularInterval) {
        x$type[i] <- j
        break()
      }
      x$type[i] <- 0
    }
  }

  x %>% dplyr::filter(type!=0)
}

